\documentclass{article}
\usepackage{amsmath}
\usepackage{amssymb}

\usepackage{graphicx}

\usepackage{fullpage}
\usepackage[parfill]{parskip}

\title{Dissertation}
\author{Cesar Esparza}

\begin{document}
\maketitle
\begin{abstract}
The objective of this work is to describe in detail how a python library is built. The main purpose of this library will be to solve normal form games through an algorithm known as genetic algorithm (...) . In order to have a better understanding of how the library was built, it is considered important to give some theoretical background of game theory and evolutionary game theory.
\\Within this written work, it will be explained how evolutionary game theory works, application of the genetic algorithm, what considerations were made for building this specific genetic algorithm, etc.
% This will need a lot of work - note that you need various abstracts, summaries
% etc\dots

\end{abstract}


\newpage
\section{Game Theory}\label{first_section}
Game theory or the theory of games is a wildly known theory, which studies the interaction of decisions and has a very wide application in sciences like economics, political sciences and psychology. These topic of the French mathematician Emile Borel who in a note in his work “La theorie du jeu et le equations integrals a noyau symetrique gauche” (Borel 1921) mentioned:
% You have misspely the french name of the article. Also, include references for
% the various applications.
\\\\ “The problems of probability and analysis suggest themselves concerning the art of war, or economic or financial speculations, are not without analogy with problems concerning games, though they generally have a higher degree of complication”.
\\\\ In 1924 Borel on his note “On games that involve chance and the skill of the Players” (Borel 1924) he mentions that “the study of games that involve at once chance and the skill of the players appears to me similarly able to furnish an opportunity for mathematical research, the applications of which might far surpass the limits of the restricted domain to which this first study is limited. /such research might be extended to very many questions in which psychological unknowns figure along with algebraic unknowns.” Then Borel continues saying that the only author who had studied problems with this focus was Joseph Bertrand in his “Calcul des Probalites” in 1889, distinguishing between mathematical and psychological aspects in an example given of a game of baccarat, but goes on stating why Bertrand study was incomplete (Borel 1924).
\\\\ Game Theory was further researched and formally presented by the Hungarian mathematician John von Neumann in 1928 with his work “Theory of Parlor Games”, stating in the introduction that “… any event – given external conditions and the participants situation (provided the latter are acting of their own free will) – may be regarded as a game of strategy if one looks at the effect it has on the participants.” (von Neumann 1928). And in 1944 John von Neumann and Oskar Morgestern published “Theory of Games and Economic Behavior” in which they established theory of games of strategy as an instrument to study problems in the economic behavior (Neumann, Morgestern 1944).
Despite of the great contribution of von Neumann and Morgestern, game theory became widely used after the Doctoral dissertation from John F. Nash was published in 1950. The some of the main arguments from Nash’s work are that he gives the possibility of analyzing games with more n-players, he introduces the concept of non-cooperative games having at least one equilibrium point and gives the idea of a “dynamical” approach to study cooperative games (Nash 1950). The last point I mentioned refers to how a cooperative game can be reduced to non-cooperative form, because the idea of a cooperative game stablished by von Neumann and Morgenstern was that cooperation was given under the assumption of in Nash’s words “players can communicate and form coalitions which will be enforced by and umpire.”(Nash 1950) , but he proves this condition is not the only one that would define a cooperative game. The work from Nash opened the possibility of a broader application of the essential concept of game theory, many people have extended the fundamental concepts adopted from Nash’s work and a lot of studies for the development of game theory have been made.
\\\\........................................
\subsection{Normal form games}\label{second_section}
........................................

\subsection{Nash Equilibrium}\label{third_section}

.......................................

\subsection{Agent-Based Modelling (ABM) and object oriented programming (OOP)}
Generally speaking agents are created entities that represent entities of the real world, and make them interact to study their behavior. One of the first known scientists to show interest in the concept of entities was John von Neumann (Wilensky, Rand 2015). He thought in the future it would be useful to have artificial machines that could reproduce autonomously, in order to represent objects such as celestial objects (Wilensky, Rand 2015). Given to the suggestion of his colleague Stanislaw Ulam, von Neumann developed a simple model of cellular automaton. In which each cell take one of multiple states, and then the changes in it are based on the history of previous states from the cell and neighboring cells (Janssen, Ostrom 2006).
\\\\In 1970 Martin Gardner published a game by the british mathematician John Conway. Which was a simplified model of cellular automata applied into what he called “Game of Life” (Janssen, Ostrom 2006). In which an infinite universe is divided into cells, each cell interact with the neighboring cells (8 cells around it), according to a set of established rules creating complicated patterns according to simple states of the cells, which are alive or dead (Rendell 2001). In 1973 in a joint paper published in Nature (Nature Publishing Group)  by Professor Maynard Smith and George R. Price describe the results of simulations made, which can be considered an example of an agent-based model (Maynard \& Price 1973).
\\\\In 1971, 1978 the economist Thomas Schelling used a chessboard in which by moving pennies and dimes he represented what he described in his work “Models of segregation” (Janssen, Ostrom 2006).  Finally another important work using agents were the simulations made by the political scientist Robert Axelrod in 1984 (Janssen, Ostrom 2006), in which he asked game theorists from different disciplines to submit a strategy which was used in the simulation of a tournament of one of the types of games called ‘prisoners’ dilemma’. Each strategy interacted with the other strategies, during a number of rounds (Axelrod 1984).
\\\\The previously mentioned works are some of the most relevant that involve this agent based modeling. Agent-based models (ABM) are being increasingly used to model complex systems.( Billari, et al 2006). Robert Axelrod in his book ‘The complexity of Cooperation’ defines ABM as the simulation of agents and their interactions. This type of modeling is different from the traditional type, and it is a type of simulation that is viewed as ‘bottom-up’ (Axelrod 1997, Billar 2006, Bonabeau 1994, Gilbert 1999) used for understanding properties of social systems (Axelrod 1997), by representing complex behaviours in the hopes of emulating some specific aspect. There are 3 ways for doing science according to Axelrod, which are induction, deduction and agent-based modeling, the latter starts like deduction with a set of explicit assumptions then it generates simulated data that can be analized inductively. And unlike induction the data that is produced comes from specific rules rather than real world data (Axelrod 1997). Joshua Epstein points ABM as a new tool for empirical research (Epstein, 2006). so it is very important to remember that our final goal with ABM is not to recreate reality, its rather for demonstrating a principal and understand how it works.
There are at least three main components to take in account when building an ABM, the number of agents with characteristic variables (agents contain data together with methods which act of the data), a set of rules and the environment in which the interaction takes place (Brunn, 2007) these will be described in further detail in the description of the simulation.In agent based modeling what matters is not how decisions are made but how the interaction is given (Brunn , 2007).
\\\\A very important step when building a simulation is to choose a programming language. For the type of simulation that will be built, object oriented programming (OOP) is appropriate. In the recent years this language has gained popularity, even that it can be traced for a long way back. Before the concept of OOP was well established, all computing languages were procedural languages, which means that it looked like he program was all contained in one long procedure all data and the logic were presented in a long code.
\\\\OOP places attention on ‘objects’ i.e. on properties, behavior or interaction with other objects (Pokkunuri) Object is the basic element. Objects possess attributes of procedures and data. Storing the data in variables and responds to messages by executing procedures (in Python called ‘methods’). The program is divided in individual objects (modules) each one can be viewed as an abstract data type. Each of the objects contain their own methods and data. (Pokkunuri). Communication between objects requesting action are usually called ‘message’. The purpose of this is that each object represent parts of whole program, but by breaking it down in modules each can be thought of as a particular action which we can relate in an easier how ideas and actions are structured in our everyday life. As an example we can think of an apple which would be our object and this apple contains attributes such as color, size, weight, etc. but it can also contain methods such as growing, changing color, falling from a tree, etc. This way of conceptualizing ideas in such conventional way in relation to our everyday life make it a perfect candidate for using in simulations. In this project OOP would simplify structuring the ABM, in which it was mentioned before we have so very defined concepts (agents, rules and environments).
\\\\To be able to work with OOP there is one idea we need to understand properly, which is the difference between class and object. A class can be thought of as a general description or blueprints of something but is not the thing itself.  And what the class is defining are abstract ideas of what was mentioned before, ‘attributes’ and ‘methods’, formally a class is defined as a template from which objects are created (Dyke, 1989). The next concept is object,  would be the "tangible" instance of the initial template which is the class(Luna 2012). To understand this correctly we can think of the class as the blueprints of something we want to build, and the object is that thing we wanted to build from the blueprints. And when creating an object the abstract ideas from the class, become specific characteristics of the object. A relevant property is inheritance, which allows a class to inherit methods and attributes from another class, this makes the class that inherits a subclass of the class it inherits from, it’s important to mention that this subclass can redefine inherited methods and can add methods that can differentiate it from the class it inherited from (Dyke, 1989).  Some other relevant properties from OOP are dynamic binding, which is not exclusive for OOP, means that the binding of operator to a particular operation takes place at the run time. Encapsulation is another and it describes the scope of unrestricted reference to the attributes of an object. An object can examine and modify its own attributes, and allows access to its attributes to other objects through accessing functions allowing it to have control over any changes requested from other variables. Data abstraction refers to how any object can be required for any information, and the fact that who requests gets what he/she asked for. (Pokkunuri, Dyke 1989)…
\\\\.........................................................

\subsection{Evolutionary game theory}
Evolutionary game theory has its roots in evolutionary biology. Even if this overview is not intended to be focused in biology some remarks from it are worth mentioning. From the 6th edition of ‘Origin of species’ Charles Darwin outlines that in nature there exist many struggles for existence. Some examples are the struggles of a species in the nature, between species and within species. Darwin stresses that the most severe struggle might be within species if they become into competition (Darwin 1872). In origin of species with the idea of all possible interactions of the ‘organic’ beings mentions that there may be infinite varied diversities of structure for each being under the changing conditions of life, and continues saying that through the course of generations, there can occur variations that can give perhaps a slightly advantage to some beings giving them a higher chance of survival and procreation. The preservation of favourable characteristics and destruction of what he called injurious, he called it natural selection or survival of the fittest (Darwin 1872). I go this far because later on we can think of the concept of fitness, as the ‘utility’ a player has in evolutionary game theory which in general terms can be called the ‘fittest’.

Fisher might have been the first to apply game theory to evolution in his study on sex ratios in 1930 (Pallen 2009) although at this time the formal definition of game theory had not been presented yet. Later in 1961 Lewontin discussed species playing against nature, and said that species should adopt the “maximin” strategy if nature presented worse-case scenarios (Maynard 1974, Sigmund 2004). In 1967 in an the article ‘Extraordinary sex ratios’ wrote in ‘Science’ William D. Hamilton uses game theory to model local competition and frequency-dependent fitness values (Sigmund 2004). Perhaps the most important contribution in evolutionary game theory was the one made by Professor John Maynard and Dr. George Price. John Maynard’s attention was first caught by an article written by George Price in 1968 for ‘Nature’ about ritualized behavior in animal contests (Maynard 1976) unpublished for being too long. Then in 1973 John Maynard and George Price published a joint paper ‘On the logic of animal conflict’ in which the mathematical concept of an evolutionary stable strategy is established, and it applies concepts of game theory to the study of conflicts between animals (Sigmund 2004).  The idea Maynard and Price presented was that concepts from game theory could be used to characterize eventually stable endpoints in the evolutionary process, with the concept of evolutionary stable strategy (McNamara 2010). It can be said that the concept of evolutionary game theory was born with the ideas of John Maynard and George Price.

Nowadays evolution by natural selection can be thought of as a game, where some behavioural patterns (often referred to as phenotypes the equivalent to strategies when related to traditional game theory) from animals are more successful than others (Carmichael 2005). Now I can relate evolutionary game theory with traditional game theory in the some essential concepts. Animals in the biological concept are equivalent to the players (agents) that participate in a game; the environment in which animals interact is comparable to the set of rules that regulate interaction in the traditional form; as mentioned before the heritable phenotypes of animals can be thought of as the strategies that players use in the traditional form; a tricky concept to relate to evolutionary game theory is the one of payoffs (utility) in traditional game theory  for this I will refer to how Maynard and Price define it in ‘The logic of animal conflict’ as the contribution the contest has made to the reproductive success of the agent (Maynard \& Price 1973) which could be the expressed in terms of fitness  (Darwin 1872) the fitness in an agent directly influences the frequency of the strategy in the population (Vincent 2005), Maynard and Price take in account three factors to be taken in account: the advantages of winning compared to losing, disadvantage of being seriously injured and disadvantage of wasting time and energy in the contest (Maynard \& Price 1973) this are not usually considered in games but I consider important mentioning. Another very important concept is equilibrium, in some evolutionary games the existence of evolutionary stable strategies (ESS) , I will not yet talk about the mathematical implications of  ESS. Roughly we can consider an ESS as a strategy that predominates in frequency in evolutionary games and that in the case of the emergence of a mutated strategy is not invaded (threatened to be reduce in number) this concept of ESS has similarities with the concept of Nash equilibria as seen by in the sense that both can be “no-regret” strategies when in a population a Nash or an ESS is played “no individual can benefit from unilaterally changing their strategy” (Vincent 2005). According to T.L. Vincent, resistance to invasion is only one of the two notions of an ESS, the second notion is convergence stability which implies that a population evolves to an ESS when its strategy composition is near but not at the ESS mentioned by Eshel in 1983, the implications of this will be discussed later.

Thinking of how the idea of evolutionary game theory was conceived from behavior of animals, comparing it to the traditional game theory, there are some characteristics that distinguish them from each other. First and perhaps one of the most relevant assumptions in traditional game theory is that every player is rational which means they make rational decisions to maximize their profits, and also they are aware of the possible payoffs of the other players and that other players are rational, also the rational players are aware of the game rules, evolutionary game theory does not make such assumption of rational players, instead the strategies are ‘hard wired’ to them.  Traditional game theory it is about choosing from different strategies looking to optimize the payoffs, whilst evolutionary game theory is to determine strategies that will endure through time. Traditional game theory as said before has a set of strategies from which it can choose, whilst in evolutionary game theory the strategies are already defined given that they are inherited although there can be present some occasional mutations. Also evolutionary game theory there will be groups of players that possess the same set of strategies and the same related payoff from these strategies, in traditional game theory each player has their own set of strategies and their own associated payoffs per strategy (Vincent 2005).  The application of evolutionary game theory in different areas of study has grown, and with this some assumptions change. For example in the biological application players do not choose their strategies and never change them, unlike in the economic application the players are people, who can choose and change their strategies (Samuelson 1997).
\\\\What is evolutionary game theory?
It can be defined as the combination of some game theoretical concepts, with the concepts of natural selection in evolution. It is a change in the focus from traditional game theory, because the main goal of evolutionary game theory is to observe the stable equilibria and how it changes through time with the interactions between the organisms (players) different behaviours (strategies), instead of only focusing in optimizing outcomes for a single game. Something important to note about the interaction is that in evolutionary biology and evolutionary game theory, the concerning interaction is between individuals of the same species. In this sense we can identify two main approaches to evolutionary game theory (McKenzie 2009). The first approach is the ‘static’ approach which is directly derived from the work of Maynard and Price, the main tool for analyzing is the ESS. The second approach through the study of the population dynamics (change in density of existing strategies) and of how the strategies evolve in the model built (McKenzie 2009).

\subsection{Evolutionary Stable Strategy (ESS)}
To explain better the concept a symmetric game will be analysed. It is important to mention that the games that we will focus on are two player games.
When describing ESS the most frequent example used is Hawk-Dove, first used by Maynard and Price in their paper “The logic of animal conflict” in 1973 which has been mentioned before. It is worth mentioning that this game has a structure of the well-known ‘prisoner’s dilemma’ game. ‘Prisoner’s dilemma’ formally presented by Albert Tucker to psychology students in Stanford University in 1950. As we may know ‘prisoner’s dilemma’ is a zero-sum game, in which two individuals who committed a crime are interrogated in separate rooms, and they are not able to exchange information with each other. So they are presented with 2 options (strategies), they can confess or not. And the interaction between the choices each one have go as follow. One confesses and the other does not, both of them confess or neither confess. Each interaction has a pay-off. From this point on I will refer to the players of the games we describe as agents.
First a general definition of the ESS. To illustrate this it will be used a similar approach to the one by Easley \& Kleinberg in “Networks, Crowds and Markets: Reasoning about a Highly connected World”.
We know that a strategy is evolutionarily stable when a population of agents can resist the invasion of emergent mutated agents (new strategy). As mentioned before in evolutionary biology as well as in evolutionary game theory, fitness can be defined as reproductive success (Kleinber 2010). Therefore agents with higher fitness value are majority in a population or in time will become majority, whereas agents will low fitness value will be minority and in time with a very high probability will disappear. The fitness value is obtained using the pay-off values from each interaction. With the following table it will be presented a clearer explanation of this.
For a symmetric strategic two-player game we have the following bimatrix.
\begin{center}
Agent 2

Agent 1
\begin{tabular}{|l|c|r|}
\hline
 & X & Y\\
\hline
X & a, a & b, c\\
\hline
Y & c, b & d, d\\
\hline
\end{tabular}
\end{center}
\begin{center}
	Figure???: General Symmetric Game
\end{center}
We assume that there exists a large population of agents that always take action X. Now we suppose that within the population appears a small group that take action Y and the   fraction representing the number of agents in this group is $\epsilon$.  Since $\epsilon$ represents the number of agents that choose Y, we can say that 1 - $\epsilon$ is the fraction of the agents that choose X.  We will assume then that the probability of an agent using X encountering another agent at uses X is 1 - $\epsilon$, and with a mutated that uses Y the probability is $\epsilon$.  With these and the values from the table ??? we build the payoff equation for the agent that use strategy X as follows:
\begin{equation}
(1-{\epsilon})a + {\epsilon}b
\end{equation}
And with the same values we build the pay-off equation for the agents using the strategy Y as follows:
\begin{equation}
(1-{\epsilon})c + {\epsilon}d
\end{equation}
For X to be an evolutionary stable strategy, we need:
\begin{equation}
(1-{\epsilon})a + {\epsilon}b > (1-{\epsilon})c + {\epsilon}d
\end{equation}
It should be easy to see that for X to be an ESS a $\>$ c for small values of $\epsilon$, on the other hand when the values of $\epsilon$ are closer to 1, for X to be ESS a = c and b $\>$ d.
Since the pay-offs for each agents are the result from the interactions, we should understand the following.
\begin{itemize}
\item $\textit{For X to be an ESS, the pay-off for interacting with X should be greater or at least equal to the pay-off that an Y gets when interacting with X.}$
\item $\textit{Or for X to be an ESS when X and Y get the same pay-off while interacting with X, X needs to get a better pay-off when interacting with Y than Y interacting with Y.}$
\end{itemize}
We see that if the previous does not hold, then $(1-{\epsilon})a + {\epsilon}b $<$ (1-{\epsilon})c + {\epsilon}d$ and therefore X is not an ESS.

\subsubsection{Evolutionary stable strategy and Nash equilibrium}
To gain a better understanding of the concepts linking ESS and Nash equilibrium, let us remember what Nash equilibrium is.
An action (strategy) profile $s^*$, where no player $\textit{i}$ can do better by choosing a different action (strategy) from $s^*_i$, holding player’s $\textit{j}$ action (strategy) $s^*_{j}$ fixed (Osborne 2004).  Including the notions of rationality we already know.
Now a similar explanation to the one given in ‘Networks, Crowds, and Markets: Reasoning about a Highly Connected World’ by Easley and Kleinber.
Looking back at table ???, we can take (X, X) as a Nash equilibrium, therefore we assume X is a best response to both players. And this would mean the following according to the arbitrary values we assumed:
\begin{center}
$\textit{a $\geq$ c}$
\end{center}
The conditions for a strategy to be evolutionary stable are the following:
\begin{center}
$\textit{a $>$ c, or a = c and b $>$ d}$
\end{center}
If $\textit{a $>$ c}$ then X would be a strict Nash equilibrium, on the other hand if $\textit{a = c and b$>$ d}$ the condition is not a strict but still a Nash equilibrium. Also we can draw the following conclusions:

\begin{itemize}
\item $\textit{If X (any strategy s) is not a Nash equilibrium, then X is not evolutionarily stable.}$
\item $\textit{If X (any strategy s) is evolutionarily stable, then X is a Nash equilibrium.}$
\item $\textit{If X (any strategy s) is a Nash equilibrium, but  $\textit{a = c and b $<$ d}$ then X is not evolutionarily stable.}$
\end{itemize}

Hoping to provide a more understandable explanation of the previous, an example with values will be used and since evolutionary game theory is originated from evolutionary biology, as many literature that defines ESS, we will use an example where the players are animals of a certain type.
\\\\Let us assume that there is a population of wolves all of the same size, but at some point in time a mutation occurs and some bigger wolves result from this. This mutation now represents the fraction $\epsilon$ of the population, and the rest of the population (small size wolves) are represented by 1 - $\epsilon$. These species of wolves as many others hunt in packs and given this cooperative nature the small size wolves share the prey in exactly half. Nevertheless the big sized wolves cannot afford to be so equally sharing, they need a bigger share of the prey since their body needs more nutrients, also given their size they have to make a greater effort when catching the prey. These two issues have made the big wolves aggressive to the other wolves whenever they compete for a share of the prey. The small size wolf avoids conflicts with other wolves, so if a big wolf attacks him after catching the prey they leave, but even with this situation most of the times the small size wolf still has a small share of the prey. A different scenario is given when two big wolves hunt a prey, they will fight each other until they are left seriously injured. This situation is costly for both. The expected pay-offs of these interactions are represented in the following table:
\begin{center}
Wolf size

\begin{tabular}{|l|c|r|}
\hline
 & Small & Big \\
\hline
Small & 5, 5 & 1, 7\\
\hline
 Big & 7, 1 & 2, 2\\
\hline
\end{tabular}
\end{center}
\begin{center}
	Figure???: Wolves Hunting
\end{center}

Now we will determine if the small size wolf is an evolutionarily stable strategy, for this we will use the pay-off formulas previously defined, and we have that in this population of wolves, the small size have a pay-off of:
\begin{center}
$(1-{\epsilon})5 + 1{\epsilon} = 5 - 4{\epsilon}$
\end{center}
While the population of bigger wolves have the following expected pay-off:
\begin{center}
$(1-{\epsilon})7 + 2{\epsilon} = 7 - 5{\epsilon}$
\end{center}
For small values of $\epsilon$ we see that the expected pay-off of the big wolves is higher than the small wolves pay-off.  This means that small wolves are not evolutionarily stable.
We can also determine if the big wolves are evolutionarily stable. We now assume that in a population of big wolves, some mutation of small wolves appear in the population in a fraction equal to $\epsilon$. Therefore the population of big wolves is now 1 - $\epsilon$. Now we determine the expected pay-off for big size wolves in this kind of population:
 \begin{center}
$(1-{\epsilon})2 + 7{\epsilon} = 2 + 5{\epsilon}$
\end{center}
And in this population, the mutated small sized wolves will have an expected pay-off of:
\begin{center}
$(1-{\epsilon})1 + 5{\epsilon} = 1 + 4{\epsilon}$
\end{center}
In this population, we can see that the expected pay-off of the big sized wolves is greater than the one for small size wolves. This means that the big size wolf population is evolutionarily stable and a strict Nash Equilibrium.

\subsubsection{How we use it}

Evolution can be thought as a game. According to the *theory of evolution* the existing organisms are the result of many different selections, in which the ancestors resulted the most fitted. These selections were the result of the interaction between the organisms of the same and other species.
\\\\For the purpose of this work, we will be focusing on the interaction between the same species. The model we will use is simplified.










\section{Python and genetic algorithm(relating evolutionary game theory)}
......................................................

\section{Library (Package)}\label{library_section}
The library is the file that contains all the components of the code. Because of the object oriented properties that Python facilitates, the code is segmented into 4 modules. According to their function the order in describing each is not relevant.

The population module contains the instructions to create a class named Agent (why agent described in ABM)the class has an initialization(\_\_init\_\_) method that takes as parameters strategies, utility and the possibility to add a label. After the initialization, another method is presented increment\_utility which is set for incrementing the agent’s utility, the criteria for this increment\_utility will be explained in another module.

\begin{itemize}
\item $\textbf{Strategies:}$ Each created agent will be assigned a strategy
\item $\textbf{Utility:}$ The utility each created agent generates after each interaction with another agent.
\item $\textbf{Label:}$ The possibility of adding a label to each created agent, to track their performance.
\end{itemize}

The environment module for this project the representation of the environment has only two characteristics. It is set to make two agents interact pairing them randomly and it also sets the rules which these paired agents use to interact. Some of the methods contained in this module make use of a module named ‘random’ from python. This module is imported when the environment module is executed.

Environment module creates a class BiMatrixRandomEnv, named after the characteristics bimatrix and random environment. This class has an initialization (\_\_init\_\_) method that takes as parameters number\_of\_agents and bimatrix, within the initialization the some variables are defined, these variables along with the parameters will now be explained:

\begin{itemize}
\item $\textbf{ Number\_of\_agents:}$ Input by user, total population of agents regardless of the type of agent(i.e. row agent or column agent).
\item $\textbf{Bimatrix}$ Input by user, bimatrix of payoffs(can be symmetric or assymetric).
\item $\textbf{Number\_of\_row\_agents:}$ Result from dividing by “2” the previously input value number\_of\_agents. And gives the number of row agents.
\item $\textbf{Number\_of\_col\_agents:}$ Result from dividing by “2” the previously input value number\_of\_agents. And gives the number of column agents.
\item $\textbf{Number\_of\_row\_strategies:}$ Number of strategies that will be available for row agents. Calculated by counting how many rows the bimatrix has.
\item $\textbf{Number\_of\_col\_strategies:}$ Number of strategies that will be available for column agents. Calculated by counting how many columns the bimatrix has.
\item $\textbf{Row\_strategies:}$ List containing the available strategies for row agents.
\item $\textbf{Col\_strategies:}$ List containing the available strategies for column agents.
\item $\textbf{Row\_agents:}$ Instances of class Agent are created according to the number\_of\_row\_agents.
\item $\textbf{Col\_agents:}$ Instances of class Agent are created according to the number\_of\_col\_agents.
\end{itemize}

After the initialization, a method ‘interact’ is defined. This method first defines a variable called “pairs” which is assigned to a function ‘randomly\_pair\_agents’ that will be explained later. It also contains a “for” loop this loop within other things contains a variable which is set to a function “strategies\_to\_utilities” which will be explained, variables in the “for” loop are the following:

\begin{itemize}
\item $\textbf{Ra}$
\item $\textbf{Ca}$
\item $\textbf{Pairs}$
\item $\textbf{Utility}$
\item $\textbf{Agent.increment\_utility}$: The increment utility function is defined in the population model. The structure for in this “for” loop is as follows:
\\ agent.increment\_utility(utility[x]) and what it does is assign the function increment utility to an agent can be ra (row\_agent) or ca (col\_agent), the “utility” in parenthesis was assigned in the previous variable, and it is only calling the value with the position x in the list. Given that we only have 2 types of players (we are using a bimatrix) x can be either 0 or 1.
\end{itemize}

Following ‘interact’ the method previously mentioned ‘strategies\_to\_utilities’ is defined. This method is in charge of obtaining the specific pair of utilities (assigned to row and column) from the ‘bimatrix’. It then returns these values to the ‘utility’ variable in the ‘interact’ method and interact uses it to assign the utilities to each agent.

After ‘strategies\_to\_utilities’ the method ‘randomly\_pair\_agents’ is defined. This method is used by ‘interact’ too, and what it does is that the previously created row and column agents that are contained in lists are randomly selected (one of each type) and then paired so they can interact.


\section{References}

Game Theory

'La theorie du jeu et le equations integrals a noyau symetrique gauche' Emile Borel (Borel 1921)

'On games that involve chance and the skill of the Players' Emile Borel (Borel 1924)

'Theory of Games and Economic Behavior' John von Neumann and Morgestern (Neumann, Morgestern 1944).

‘An Introduction to Game Theory’ by Martin J. Osborne 2004. Oxford University Press.

‘Non-cooperative Games' by John F. Nash 1951

'An Introduction to Agent-Based Modeling: Modeling Natural, Social, and...', By Uri Wilensky, William Rand. (Wilensky, et al 2015)

'Empirically based, agent-based models' Marco A. Janssen and Elinor Ostrom.

'The Evolution of Cooperation', R. Axelrod 1984

'A Turing Machine in Conway’s Game of Life', Paul Rendell (Rendell 2001)

'Agent-Based Computational Models and Generative Social Science', Joshua M. Epstein 2006

'Agent-Based Computational Modelling: An Introduction', Francesco Billari, Thomas Fent, Alexia Prskawetz, Jurgen Scherffran.

'Agent-Based Computational Economics', Charlotte Brunn.

'Economic Simulations I Swarm: Agent Based Modelling' Francesco Luna, Benedikt Stefansson 2012.


Evolutionary Game Theory

‘Origin of species by means of natural selection or the preservation of favoured races in the struggle for life’ 6th edition Charles
Darwin 1872.

‘The Rough guide to evolution’ Mark Pallen 2009

‘The theory of games and the evolution of animal conflicts’ John Maynard Smith 1974 j. theor. Biol. (1974) 47  209

‘John Maynard Smith and evolutionary game theory’ Karl Sigmund 2004

‘Extraordinary sex ratios’ William D Hamilton 1967

‘Evolutionary game theory, natural selection and darwinian dynamics’ Thomas L. Vincent and Joel S.Brown 2005

‘Evolutionary Game theory’ John McNamara and Franz Weissing from the book ‘Social Behaviour: Genes, Ecology and Evolution’ by
Tamas Szekely, Allen J. Moore and Jan Komdeur. Cambridge press 2010.

‘Modelling in behavioural Ecology: An Introductory Text’ Dennis Lendrem (1986)

 'Antlers, Intraspecific Combat, and Altruism', George Price to Nature in August 1968 (Unpublished)

‘Evolution and the Theory of Games in situations characterized by conflict of interest…’ John Maynard Smith 1976

‘A guide to game theory’ Fiona Carmichael 2005 book

‘The Logic of Animal Conflict' J. Maynard Smith and G. R. Price. Nature vol. 246 1973

‘Evolutionary games and Equilibrium selection’ Larry Samuelson MIt 1997
Alexander, J. McKenzie, 'Evolutionary Game Theory', The Stanford Encyclopedia of Philosophy (Fall 2009 Edition), Edward N. Zalta (ed.), URL = <http://plato.stanford.edu/archives/fall2009/entries/game-evolutionary/>.

'The mathematics of Tucker: A Sampler', Albert William Tucker 1983

'Albert William Tucker', JJ O’Connor and E F Robertson 2010 .

'Networks, Crowds, and Markets: Reasoning about a Highly Connected World', by David Easley and Jon Kleinberg. Cambridge University Press 2010.


\end{document}
