\section{Game Theory}
\label{Literature:gt}
Game theory studies the interaction of decisions of interdependent participants in an environmentment.Applications of game theory in economics include: market competition, setting import and exporting tariffs, agreements in wages between employers and employees ,and auctions $\cite{gibbons1992primer}$. In political sciences some examples include raising more money than other candidates when running for a political position, what to do when the opposition is considered “weak” or “strong”, accepting new policies if the outcomes are not certain,  an example is when a jury has to sentence a defendant among others $\cite{mccarty2007political}$. In psychology, when studying the behavior of individuals with respect of others, although application of strict assumptions of game theory such as rationality been assumed in the same level for all participants still is a controversial topic for the application of game theory in many areas of social psychology $\cite{rapoport1999game}$ $\cite{colman2003cooperation}$. In biology the subfield related is evolutionary game theory, and will be described later. 
\\\\Studies that started exploring the potential solution of some games can be traced back to 1713  when James Waldegrave in a letter communicated a mixed solution for a two person game to his colleague Pierre Remond de Montmort $\cite{hykvsova2004several}$ . Since Waldegrave many others did studies that now we relate to game theory $\cite{watson2013strategy}$. The french mathematician Emile Borel 1924  on his note ``On games that involve chance and the skill of the Players'' $\cite{borel1953games}$ mentions  ``the study of games that involve at once chance and the skill of the players appears to me similarly able to furnish an opportunity for mathematical research, the applications of which might far surpass the limits of the restricted domain to which this first study is limited. /such research might be extended to very many questions in which psychological unknowns figure along with algebraic unknowns.'' Then Borel continues saying that the only author who had studied problems with this focus was Joseph Bertrand in his ``Calcul des Probalites'' in 1889, distinguishing between mathematical and psychological aspects in an example given of a game of baccarat, but goes on stating why Bertrand study was incomplete $\cite{borel1953games}$.
\\\\ Game Theory was further researched and formally presented by the Hungarian mathematician John von Neumann in 1928 with his work “Theory of Parlor Games”, stating in the introduction that ``… any event – given external conditions and the participants situation (provided the latter are acting of their own free will) – may be regarded as a game of strategy if one looks at the effect it has on the participants.'' $\cite{von1928theory}$. And in 1944 John von Neumann and Oskar Morgestern published ``Theory of Games and Economic Behavior'' in which they established theory of games of strategy as an instrument to study problems in the economic behavior $\cite{von2007theory}$. 
Despite of the great contribution of von Neumann and Morgestern the application of game theory was limited. Game theory became widely used after the Doctoral dissertation from John F. Nash was published in 1950. Some of the main arguments from Nash’s work are that he gives the possibility of analyzing games with more n-players, he introduces the concept of non-cooperative games having at least one equilibrium point, and gives the idea of a “dynamical” approach to study cooperative games $\cite{nash1951non}$. The last point I mentioned refers to how a cooperative game can be reduced to non-cooperative form, because the idea of a cooperative game established by von Neumann and Morgenstern was that cooperation was given under the assumption described in Nash’s words “players can communicate and form coalitions which will be enforced by and umpire.” $\cite{nash1951non}$ , but he proves this condition is not the only one that would define a cooperative game. The work from Nash opened the possibility of a broader application of the essential concept of game theory, many people have extended the fundamental concepts adopted from Nash's work and a lot of studies for the development of game theory have been made since.

\subsection{Normal form games}\label{second_section}
Watson 2013 in $\cite{watson2013strategy}$  mentions that there are several mathematical ways to describe games. In game theory there are two most common ways to represent a game called extensive form and normal form. The extensive form which represents in the form of a game tree the different actions that can be taken by each player. Starts with an initial node from which it branches out representing the possible choices and then after each branch another node is placed where a second player has other choices that branch out,  and keeps on until reaching the end of the tree where the payoff for each sequence(following the branches) for the path are represented. For the purpose of this project, the normal form representation of a game will be used and the basic information about it is the following.
The normal form games, also known as strategic form of games, usually have the following elements:
\begin{itemize}
\item $\textbf{Players}$ A finite set of $\textit{N}$ players.
\item $\textbf{Strategies:}$ A set S$_i$ for each player $\textit{i}$ $\in$ $\textit{N}$. Which as we have discussed represents the action a player chooses.
\item $\textbf{Payoffs:}$ Payoff functions represented for each player represented by $\textit{u$_i$: S$_1$ x S$_2$ x}$ ... $\textit{ x S$_N$}$ $\rightarrow$ $\mathbb{R}$ .Which represent the payoff each player obtain after interacting with each other.
\end{itemize}

For the purpose of this project, the number of players will be $\textit{N}$ = 2 taking the following assumptions from $\cite{knight2014gt}$ we will represent the game with a $\textbf{ bi-matrix}$. And we will assume that  $\textbf{S$_1$ = \{s$_i$ $|$ 1  $\geq$ i $\geq$ n\}}$ and $\textbf{S$_2$ = \{s$_j$ $|$ 1  $\geq$ j $\geq$ n\}}$ this will be the $\textbf{bi-matrix}$ for this game :
\begin{table}[h]
\begin{center}
Player 2

Player 1
\begin{tabular}{|l|c|c|c|c|}
\hline
& s$_1$ & s$_2$ & ... & s$_j$\\ 
\hline
r$_1$ & u$_1$(r$_1$,s$_1$), u$_2$(r$_1$,s$_1$) & u$_1$(r$_1$,s$_2$), u$_2$(r$_1$,s$_2$) & ... &  u$_1$(r$_1$,s$_j$), u$_2$(r$_1$,s$_j$\\
\hline
r$_2$ & u$_1$(r$_2$,s$_1$), u$_2$(r$_2$,s$_1$) & u$_1$(r$_2$,s$_2$), u$_2$(r$_2$,s$_2$) & ... &  u$_1$(r$_2$,s$_j$), u$_2$(r$_2$,s$_j$\\
\hline
. & . & . & ... & .\\
. & . & . & ... & .\\
. & . & . & ... & .\\
\hline
r$_i$ & u$_1$(r$_i$,s$_j$), u$_2$(r$_i$,s$_j$) & u$_1$(r$_i$,s$_j$), u$_2$(r$_i$,s$_j$) & ... &  u$_1$(r$_i$,s$_j$), u$_2$(r$_i$,s$_j$)\\
\hline
\end{tabular}
\caption{Normal form game bi-matrix}
\label{tab:normformgame}
\end{center}
\end{table}

We can see that each intersection of row and column has two utility functions. The first utility function represents the payoff for the row player and the second utility function represents the payoff for the column player. Utilities can be of type ordinal, which is used only to rank the alternatives from better to worse, or cardinal which indicates that the value assigned is meaningful and represents the satisfaction of the player $\cite{mccarty2007political}$.


\subsection{Nash equilibrium}\label{third_section}
John Nash writes in his dissertation ``... an equilibrium point is an n-tuple $\textbf{s}$ so that each player's mixed strategy maximizes his payoff if the strategies of the others are held fixed. Thus each player's strategy is optimal against those of the others.'' $\cite{nash1951non}$.  After this he describes under what circumstances a mixed strategy behaves as a pure strategy. Nowadays the definition of Nash's equilibrium point is known as a Nash equilibrium and we will commonly find the phrase "no regrets" when describing the Nash equilibrium and this is because paraphrasing Nash, no player in the game could have had a better payoff given the action chosen by her opponent. For an N player normal form game Nash equilibrium $\cite{knight2014gt}$ gives the following definition:
\begin{equation}
u_i(\hat{s}) \geq u_i(\bar{s}_i, \wedge{s}_{-i}) \forall i
\end{equation}
 In a two player game, this means each player $\textit{i}$ has a set of strategies $\textit{S}$, and a pair of strategies $(\hat{r}, \hat{s})$ so pure Nash equilibrium can be defined as:
\begin{equation}
u_1(\hat{r}, \hat{s}) \geq u_1(r, \hat{s}) \forall r \in S_1   \text{ and }  u_2(\hat{r}, \hat{s}) \geq u_2(\hat{r}, s) \forall r \in S_1
\end{equation}
An ``easy'' way to find Nash equilibria in games with pure Nash equilibria is by looking at the table in the normal form that holds the strategies and payoffs for each player, and underlining the best response for each player when the other player's strategies are held fixed.
As an example we will use the prisoner's dilemma normal form, and first we hold fixed player's 2 strategies and we underline the best response for player 1 for each of player's 2 strategies.

\begin{table}[h]
\begin{center}
Player 2

Player 1
\begin{tabular}{|l|c|c|}
\hline
 & Cooperate & Defect\\ 
\hline
Cooperate & 3, 3 & 0, 5\\
\hline
Defect & \underline{5}, 0 & \underline{1}, 1\\
\hline
\end{tabular}
\caption{Best responses for player 1}
\label{tab:normformbr1}
\end{center}
\end{table}

In this first table we have that defect is the best response for player 1 in the case where player 2 chooses either of the strategies. 
Now we explore the options holding player 1's strategies fixed and we have the following.

\begin{table}[h]
\begin{center}
Player 2

Player 1
\begin{tabular}{|l|c|c|}
\hline
 & Cooperate & Defect\\ 
\hline
Cooperate & 3, 3 & 0, \underline{5}\\
\hline
Defect & 5, 0 & 1, \underline{1}\\
\hline
\end{tabular}
\caption{ Best responses for player 2}
\label{tab:normformbr2}
\end{center}
\end{table}

And now we only take the strategies that are best responses for both players. Remembering that is the strategy where neither of the players have any reason to change from given that whatever the other player choice is it will always give them the best payoff available for the interaction.
 \begin{table}[h]
\begin{center}
Player 2

Player 1
\begin{tabular}{|l|c|c|}
\hline
 & Cooperate & Defect\\ 
\hline
Cooperate & 3, 3 & 0, 5\\
\hline
Defect & 5, 0 & \underline{1}, \underline{1}\\
\hline
\end{tabular}
\caption{ Nash equilibrium with best responses.}
\label{tab:normformbr3}
\end{center}
\end{table}

\section{Evolutionary game theory}\label{EGT}
A branch of game theory which is of great interest for the purpose of this project is `Evolutionary game theory'. Evolutionary game theory has its roots in evolutionary biology. Even if this overview is not intended to be focused in biology some remarks from it are worth mentioning. In the 6th edition of Charles Darwin's work ``Origin of species'' he outlines that in nature there exist many struggles for existence. Some examples are the struggles of a species in the nature, between species and within species. Darwin stresses that the most severe struggle might be within species if they become into competition $\cite{darwin1872origin}$. Darwin 1872 mentions that there may be infinite varied diversities of structure for each being under the changing conditions of life, and continues saying that through the course of generations, there can occur variations that can give perhaps a slightly advantage to some beings giving them a higher chance of survival and procreation. The preservation of favourable characteristics and destruction of what he called injurious, was called `natural selection' or `survival of the fittest' $\cite{darwin1872origin}$. I go this far because later on we can think of the concept of fitness, as the ‘utility’ a player has in evolutionary game theory which in general terms can be called the ‘fitness’.

Perhaps the most important contribution in evolutionary game theory was the one made by Professor John Maynard and Dr. George Price. John Maynard’s attention was first caught by the article ``Antlers, Intraspecific Combat, and Altruism'', written by George Price in 1968 for `Nature’ about ritualized behavior in animal contests $\cite{smith1976evolution}$ unpublished for being too long. Then in 1973 John Maynard and George Price published a joint paper ‘On the logic of animal conflict’ in which the mathematical concept of an evolutionary stable strategy is established, and it applies concepts of game theory to the study of conflicts between animals $\cite{sigmund2004maynard}$.  The idea Maynard and Price presented was that concepts from game theory could be used to characterize eventually stable endpoints in the evolutionary process, with the concept of evolutionary stable strategy $\cite{mcnamara2010evolutionary}$. It can be said that the concept of evolutionary game theory was born with the ideas of John Maynard and George Price.

Nowadays evolution by natural selection can be thought of as a game, where some behavioural patterns (often referred to as phenotypes the equivalent to strategies when related to traditional game theory) from animals are more successful than others $\cite{carmichael2005guide}$. Animals in the biological concept are equivalent to the players (agents) that participate in a game; the environment in which animals interact is comparable to the set of rules that regulate interaction in the traditional concept of games; as mentioned before the heritable phenotypes of animals can be thought of as the strategies that players use in the traditional concept of games; a tricky concept to relate to evolutionary game theory is the one of payoffs (utility) in traditional game theory  for this I will refer to how Maynard and Price defined it in `The logic of animal conflict' and this was as the contribution the contest has made to the reproductive success of the organism (agent) $\cite{smith1973lhe}$ which could be the expressed in terms of fitness  $\cite{darwin1872origin}$ the fitness in an organism (agent) directly influences the frequency of the strategy in the population $\cite{vincent2005evolutionary}$, Maynard and Price take in account three factors: the advantages of winning compared to losing, disadvantage of being seriously injured and disadvantage of wasting time and energy in the contest $\cite{smith1973lhe}$ this are not usually considered in games but I consider important mentioning. Another very important concept is equilibrium, in some evolutionary games the existence of evolutionary stable strategies (ESS) , the mathematical representation of  ESS will be presented later in this project. Roughly we can consider an ESS as a strategy that predominates in frequency in evolutionary games through time and that in the case of the emergence of a mutated strategy is not invaded (threatened to be reduce in number) this concept of ESS has similarities with the concept of Nash equilibria as seen by in the sense that both can be ``no-regret'' strategies when in a population a Nash or an ESS is played ``no individual can benefit from unilaterally changing their strategy" $\cite{vincent2005evolutionary}$.  

Certain characteristics distinguish traditional game theory from evolutionary game theory. First and perhaps one of the most relevant assumptions in traditional game theory is that every player is rational which means they make rational decisions to maximize their profits,  they are also aware of the possible payoffs of the other players and that other players are rational, and the rational players are aware of the game rules, evolutionary game theory does not make such assumption of rational players, instead the strategies are ‘hard wired’ to them in other words they are assigned to each player with no possibility of the player choosing.  Traditional game theory is about choosing from different strategies looking to optimize the payoffs, whilst evolutionary game theory is used to determine strategies that will endure through time. Traditional game theory as said before has a set of strategies from which players can choose, whilst in evolutionary game theory the strategies are already defined (given that they are inherited), although there can be present some occasional mutations. Also in evolutionary game theory there will be groups of players that possess the same set of strategies and the same related payoff for these strategies, in traditional game theory each player has their own set of strategies and their own associated payoffs per strategy $\cite{vincent2005evolutionary}$.  The application of evolutionary game theory in different areas of study has grown, and with this some assumptions change. For example in the biological application players do not choose their strategies and never change them, unlike in the economic application the players are people, who can choose and change their strategies (Samuelson 1997)$\cite{samuelson1998evolutionary}$.
\\\\$\textbf{What is evolutionary game theory?}$
\\\\It can be defined as the combination of some game theoretical concepts, with the concepts of natural selection in evolution. It is a change in the focus from traditional game theory, because the main goal of evolutionary game theory is to observe the stable equilibria and how it changes through time with the interactions between the organisms (players) with their own different behaviours (strategies), instead of only focusing in optimizing outcomes for a single game. Something important to note about the interaction is that in evolutionary biology and evolutionary game theory, the concerning interaction is between individuals of the same species. In this sense we can identify two main approaches to evolutionary game theory $\cite{mckenzie2009evolutionary}$. The first approach is the ‘static’ approach which is directly derived from the work of Maynard and Price, the main tool for analyzing is the ESS. The second approach through the study of the population dynamics (change in density of existing strategies) and of how the strategies evolve in the model built $\cite{mckenzie2009evolutionary}$.

\subsection{Evolutionary stable strategy (ESS)}\label{EES}
To give an easier explanation of ESS, the concept will be analysed with a symmetric game. It is important to mention that the games that will be used in this project are two player games. 
When describing ESS the most frequent example used is Hawk-Dove, first used by Maynard and Price in their paper ``The logic of animal conflict'' in 1973 which has been mentioned before. It is worth mentioning that this game has the structure of the well-known ‘prisoner's dilemma’ game. The `Prisoner's dilemma’  was formally presented by Albert Tucker to psychology students in Stanford University in 1950. As we may know ‘prisoner’s dilemma’ is a game in which two individuals who committed a crime are interrogated in separate rooms, and they are not able to exchange information with each other. So they are presented with 2 options (strategies), they can confess or not. And the interaction between the choices each one have go as follow. One confesses and the other does not, both of them confess or neither confess. Each interaction has a pay-off. From this point on the use of the word `player' and  I will refer to the players of the games we describe as agents.
First a general definition of the ESS should be done. To illustrate this it will be used as a guide the approach from Easley \& Kleinberg in ``Networks, Crowds and Markets: Reasoning about a Highly connected World''$\cite{easley2010networks}$ in definition of ESS since it is considered suitable for this project.
We know that a strategy is evolutionarily stable when a population of agents can resist the invasion of emergent mutated agents (new strategy). As mentioned before in evolutionary biology as well as in evolutionary game theory, fitness can be defined as reproductive success $\cite{easley2010networks}$. Therefore agents with higher fitness value are majority in a population or in time will become majority, whereas agents will low fitness value will be minority and in time with a very high probability will disappear. The fitness value is obtained using the pay-off values from each interaction. An explanation will be given using the table $\ref{tab:gensymgame}$ to illustrate an example, the table is taken from Easley \& Kleinberg 2010 $\cite{easley2010networks}$.
For a symmetric strategic two-player game we have the following bimatrix.

\begin{table}[h]
\begin{center}
Agent 2

Agent 1
\begin{tabular}{|l|c|r|}
\hline
 & X & Y\\ 
\hline
X & a, a & b, c\\
\hline
Y & c, b & d, d\\
\hline
\end{tabular}
\end{center}
\caption{ General Symmetric Game.}
\label{tab:gensymgame}
\end{table}

We assume that there exists a large population of agents that always take action X. Now we suppose that within the population appears a small group that takes action Y and the   fraction representing the number of agents in this group is $\epsilon$.  Since $\epsilon$ represents the number of agents that choose Y, we can say that 1 - $\epsilon$ is the fraction of the agents that choose X.  We will assume then that the probability of an agent using X encountering another agent at uses X is 1 - $\epsilon$, and with a mutated that uses Y the probability is $\epsilon$.  With these and the values from the figure $\ref{tab:gensymgame}$  we build the payoff equation for the agent that use strategy X as follows:
\begin{equation}
(1-{\epsilon})a + {\epsilon}b
\end{equation}
And with the same values from the table and the proportions in the population, we build the pay-off equation for the agents using the strategy Y as follows:
\begin{equation}
(1-{\epsilon})c + {\epsilon}d
\end{equation}
For X to be an evolutionary stable strategy, we need:
\begin{equation}
(1-{\epsilon})a + {\epsilon}b > (1-{\epsilon})c + {\epsilon}d
\end{equation}
For X to be an ESS a $>$ c for small values of $\epsilon$, on the other hand when the values of $\epsilon$ are closer to 1, for X to be ESS a = c and b $>$ d.
Since the pay-offs for each agents are the result from the interactions, we should understand the following  $\cite{easley2010networks}$:
\begin{itemize}
\item For X to be an ESS, the pay-off for interacting with X should be greater or at least equal to the pay-off that a strategy Y gets when interacting with X.
\item Or for X to be an ESS when X and Y get the same pay-off while interacting with X, X needs to get a better pay-off when interacting with Y than Y interacting with Y.
\end{itemize}
We see that if the previous does not hold, then $(1-{\epsilon})a + {\epsilon}b < (1-{\epsilon})c + {\epsilon}d$ and therefore X is not an ESS.
So far we have defined the possibility of having a pure strategy dominating in time. There also exist a case where pure strategies can be played with different probabilities, this will prevent from having a pure strategy equilibria causing an evolutionarily stable mixed strategy. I consider important to mention that when only a pure strategy is played by any entity, it means that it is palyed with a probability of 1 (100\%) , if a mixed strategy is to be played it means that proportion is distributed among the possible effective strategies. In Osborne 2004$\cite{osborne2004introduction}$, we can find a fragment of Maynard Smith's work where he explains that  if randomizing between strategies offers an advantage it can evolve in time, therefore it is possible to be inherited from parents. 

\subsection{Evolutionary stable strategy and Nash equilibrium} \label{EESNE}
To gain a better understanding of the concepts linking ESS and Nash equilibrium, let us remember what Nash equilibrium is. 
An action (strategy) profile $s^*$, where no player $\textit{i}$ can do better by choosing a different action (strategy) from $s^*_i$, holding player’s $\textit{j}$ action (strategy) $s^*_{j}$ fixed $\cite{osborne2004introduction}$.  Including the notions of rationality we already know.   
Now a similar explanation to the one given in `Networks, Crowds, and Markets: Reasoning about a Highly Connected World'  by Easley and Kleinberg$\cite{easley2010networks}$ will be used.
Looking back at table $\ref{tab:gensymgame}$, we can take (X, X) as a Nash equilibrium, therefore we assume X is a best response to both players. And this would mean the following according to the arbitrary values we assumed:
\begin{equation}
{a \geq c}
\end{equation}
The conditions for a strategy to be evolutionarily stable are the following:
\begin{equation}
{a > c, \text{ or } a = c \text{ and } b > d}
\end{equation}
If $\textit{a $>$ c}$ then X would be a strict Nash equilibrium, on the other hand if $\textit{a = c and b$>$ d}$ the condition is not a strict but still a Nash equilibrium.From Easley 2010 $\cite{easley2010networks}$ we can draw the following conclusions:

\begin{itemize}
\item $\textit{If X (any strategy s) is not a Nash equilibrium, then X is not evolutionarily stable.}$ 
\item $\textit{If X (any strategy s) is evolutionarily stable, then X is a Nash equilibrium.}$ 
\item $\textit{If X (any strategy s) is a Nash equilibrium, but  $\textit{a = c and b $<$ d}$ then X is not evolutionarily stable.}$
\end{itemize}

Hoping to provide a more understandable explanation of the previous, an example with values will be used and since evolutionary game theory is originated from evolutionary biology, as many literature that defines ESS, we will use an example where the players are animals of a certain type.
\\\\Let us assume that there is a population of wolves all of the same size, but at some point in time a mutation occurs and some bigger wolves result from this. This mutation now represents the fraction $\epsilon$ of the population, and the rest of the population (small size wolves) are represented by 1 - $\epsilon$. These species of wolves as many others hunt in packs and given this cooperative nature the small size wolves share the prey in exactly half. Nevertheless the big sized wolves cannot afford to be so equally sharing, they need a bigger share of the prey since their body needs more nutrients, also given their size they have to make a greater effort when catching the prey. These two issues have made the big wolves aggressive to the other wolves whenever they compete for a share of the prey. The small size wolf avoids conflicts with other wolves, so if a big wolf attacks him after catching the prey they leave, but even with this situation most of the times the small size wolf still has a small share of the prey. A different scenario is given when two big wolves hunt a prey, they will fight each other until they are left seriously injured. This situation is costly for both. The expected pay-offs of these interactions are represented in the following table:

\begin{table}[h]
\begin{center}
Wolf size


\begin{tabular}{|l|c|r|}
\hline
 & Small & Big \\ 
\hline
Small & 5, 5 & 1, 7\\
\hline
 Big & 7, 1 & 2, 2\\
\hline
\end{tabular}
\caption{Wolves Hunting}
\label{tab:wolveshunt}
\end{center}
\end{table}

Now we will determine if the small size wolf is an evolutionarily stable strategy, for this we will use the pay-off formulas previously defined, and we have that in this population of wolves, the small size have a pay-off of:
\begin{equation}
(1-{\epsilon})5 + 1{\epsilon} = 5 - 4{\epsilon}
\end{equation}
While the population of bigger wolves have the following expected pay-off:
\begin{equation}
(1-{\epsilon})7 + 2{\epsilon} = 7 - 5{\epsilon}
\end{equation}
For small values of $\epsilon$ we see that the expected pay-off of the big wolves is higher than the small wolves pay-off.  This means that small wolves are not evolutionarily stable.
We can also determine if the big wolves are evolutionarily stable. We now assume that in a population of big wolves, some mutation of small wolves appear in the population in a fraction equal to $\epsilon$. Therefore the population of big wolves is now 1 - $\epsilon$. Now we determine the expected pay-off for big size wolves in this kind of population:
 \begin{equation}
(1-{\epsilon})2 + 7{\epsilon} = 2 + 5{\epsilon}
\end{equation}
And in this population, the mutated small sized wolves will have an expected pay-off of:
\begin{equation}
(1-{\epsilon})1 + 5{\epsilon} = 1 + 4{\epsilon}
\end{equation}
In this population, we can see that the expected pay-off of the big sized wolves is greater than the one for small size wolves. This means that the big size wolf population is evolutionarily stable and a strict Nash Equilibrium.

\subsection{Genetic algorithm} \label{sec:genalg}
 In 1960s and 1970s James Holland with students and colleagues from University of Michigan developed the genetic algorithm $\cite{melanie1999introduction}$. Holland's goal was to study the phenomenon of adaptation of processes in natural systems and develop ways in which the mechanics of adaptation might be imported to computer systems. Holland introduced a population-based algorithm with crossover, inversion and mutation $\cite{melanie1999introduction}$.

Genetic algorithm is a type of evolutionary algorithm. In general terms it can be seen as an imitation of biological evolution for problem solving. A genetic algorithm combines the survival of the fittest with  structured yet randomized information exchange. Genetic algorithms are no simple random walk, they exploit historical information to speculate on new search points expecting improved performance. The main research in genetic algorithms revolves around robustness, the balance between eficiency and efficacy for survival in different environments $\cite{golberg1989genetic}$ Genetic algorithms are blind, they perform an effective search only requiring payoff values associated with individual strings $\cite{golberg1989genetic}$.  Melanie 1999 mentions that although there no widely accepted definition for genetic algorithm in the evolutionary - computational community, most methods self called "genetic algorithm" have in common the use of population of chromosomes, selection according to fitness, crossover to produce new offsprings, and random mutation of the new offspring.  

\section{Approaches} \label{ABMOOP}
When building a computer simulations focused in social studies there are two concepts that can be helpful to make the simulation process easier to build: Agent-based modeling (ABM) and object oriented programming(OOP). Agent-based modeling is a good approach to have a concept of how to represent the elements that are in someway the subjects of study and object oriented programming (OOP) can help to represent agents with there individual characteristics, their environment and any other factors that have an impact in the intended study, given its versatile style for variables manipulation.
\subsection{Agent-Based Modelling (ABM)}
Generally speaking in ABM agents are entities created to represent entities of the real world, and make them interact to study their behavior. One of the first known scientists to show interest in the concept of entities was John von Neumann $\cite{wilensky2015introduction}$. He thought in the future it would be useful to have artificial machines that could reproduce autonomously, in order to represent objects such as celestial objects $\cite{wilensky2015introduction}$. Given to the suggestion of his colleague Stanislaw Ulam, von Neumann developed a simple model of cellular automaton. In which each cell take one of multiple states, and then the changes in it are based on the history of previous states from the cell and neighboring cells $\cite{janssen2006empirically}$.
\\\\In 1970 Martin Gardner published a game by the british mathematician John Conway. Which was a simplified model of cellular automata applied into what he called “Game of Life” $\cite{janssen2006empirically}$. In which an infinite universe is divided into cells, each cell interact with the neighboring cells (8 cells around it), according to a set of established rules creating complicated patterns according to simple states of the cells, which could be in one of two states (alive or dead) $\cite{rendell2001turing}$. In 1973 in a joint paper published in `Nature' (Nature Publishing Group)  by Professor Maynard Smith and George R. Price describe the results of simulations made, which can be considered an example of an agent-based model $\cite{smith1974theory}$.
\\\\In 1971 the economist Thomas Schelling used a chessboard in which by moving pennies and dimes he represented what he described in his work ``Models of segregation'' $\cite{janssen2006empirically}$.  Finally another important work that used agents were the simulations made by the political scientist Robert Axelrod in 1984 $\cite{janssen2006empirically}$, in which he asked game theorists from different disciplines to submit a strategy each, these strategies were used for simulating a tournament of a type of game called `prisoners’ dilemma'. Each strategy interacted with the other strategies, during a number repetitions and for each repetition  a determined number of rounds $\cite{axelrod1984evolution}$ the objective was to see if `cooperative' strategies can evolve in an environment where `selfish' strategies exist.
\\\\The previously mentioned works are some of the most relevant that involve this agent based modeling. Agent-based models (ABM) are being increasingly used to model complex systems $\cite{billari2006agent}$. Robert Axelrod in his book `The complexity of Cooperation’ defines ABM as the simulation of agents and their interactions. This type of modeling is different from the traditional type, and it is a type of simulation that is viewed as `bottom-up’ $\cite{axelrod1997complexity}$ used for understanding properties of social systems $\cite{axelrod1997complexity}$, by representing complex behaviours in the hopes of emulating some specific aspect. There are 3 ways for doing science according to Axelrod, which are induction, deduction and agent-based modeling, the latter starts like deduction with a set of explicit assumptions then it generates simulated data that can be analized inductively. And unlike induction the data produced comes from specific rules rather than real world data $\cite{axelrod1997complexity}$. Joshua Epstein points ABM as ``a new tool for empirical research" $\cite{epstein2007agent}$. So it is very important to remember that our final goal with ABM is not to recreate reality, its rather for demonstrating a principal and understand how it works. 
There are at least three main components to take in account when building an ABM, the number of agents with characteristic variables (agents contain data together with methods which act of the data), a set of rules forthe interaction and the environment in which the interaction takes place $\cite{bruun2004agent}$ this will be described in further in the description of the simulation. In agent based modeling what matters is not how decisions are made but how the interaction is given $\cite{bruun2004agent}$. 
\\\\A very important step when building a simulation is to choose a programming language. Axelrod mentions that a good agent based model should achieve three goals: validity this is for the program to implement the model correctly, usability which involves the fact that the person building the model and other users can run the program, interpret the output and understand how it works, and the third point is extendability which means the program should be adaptable for new uses in the future $\cite{axelrod1997complexity}$. For the type of simulation that was built for this project, object oriented programming (OOP) is appropriate. In the recent years this language has gained popularity, but it can be traced for a long way back. Before the concept of OOP was well established, all computing languages were procedural languages, which means that it looked like the program was all contained in one long procedure all data and the logic were presented in a long code.

\subsection{Object Oriented Programming (OOP)} \label{OOP}
OOP's concern is on `objects' $\cite{pokkunuri1989object}$ this objects can be anything one can think of i.e. an action, a thing, a person, a place, of course they have to be well defined. Object is the basic element. Objects possess attributes of procedures and data. Storing the data in variables and responds to messages by executing procedures (in Python called ‘methods’). The program is divided in individual objects (modules) each one can be viewed as an abstract data type. Each of the objects contain their own methods and data $\cite{pokkunuri1989object}$. Communication between objects requesting action can be called ‘message’. The purpose of this is that each object represent parts of whole program, but by breaking it down in modules each can be thought of as a particular action which we can relate in an easier how ideas and actions are structured in our everyday life. As an example we can think of an apple which would be our object and this apple contains attributes such as color, size, weight, etc. but it can also contain methods such as growing, changing color, falling from a tree, etc. This way of conceptualizing ideas in such conventional way in relation to our everyday life make it a perfect candidate for using in simulations. In this project OOP would simplify structuring the ABM, in which it was mentioned before we have so very defined concepts (agents, rules and environments). 
\\\\To be able to work with OOP there is an important concept to understand, the difference between class and object. A class can be thought of as a general description or blueprints of something but is not the thing itself.  What the class is defining are abstract ideas of what was mentioned before, `attributes’ and `methods’, formally a class is defined as a template from which objects are created $\cite{dyke1989object}$. The next concept is object,  would be the ``tangible'' instance of the initial template which is the class$\cite{luna2012economic}$. To understand this correctly we can think of the class as the blueprints of something we want to build, and the object is that thing we wanted to build from the blueprints. When creating an object the abstract ideas from the class, become specific characteristics of the object. A relevant property is inheritance, which allows a class to inherit methods and attributes from another class, this makes the class that inherits a subclass of the class it inherits from, it’s important to mention that this subclass can redefine inherited methods and can add methods that can differentiate it from the class it inherited from $\cite{dyke1989object}$.  Some other relevant properties from OOP are dynamic binding, which is not exclusive for OOP, means that the binding of operator to a particular operation takes place at the run time. Encapsulation is another and it describes the scope of unrestricted reference to the attributes of an object. An object can examine and modify its own attributes, and allows access to its attributes to other objects through accessing functions allowing it to have control over any changes requested from other variables. Data abstraction refers to how any object can be required for any information, and the fact that who requests gets what he/she asked for $\cite{pokkunuri1989object}$. 

With the created code when running the simulation individual agents with individual characteristics are created (for this project the characteristics are that they can posses a strategy and everytime they intreract they are able to accumulate an individual utility), and they are set to interact in a certain way under determined rules, the final goal will be to have a general perspective of how the interaction of these individual objects leads to a resulting conclusion. In this case we will be able to observe how agents represent different strategies and what is the result of the interaction which will be how one strategy dominates another or how they interact and find a balance. The language chosen for writing the code is Python which is a high level programming language, designed by Guido van Rossum. It serves general programming purposes and it is a very effective object oriented language.

